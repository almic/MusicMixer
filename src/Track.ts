import AudioSourceNode from './AudioSourceNode.js';
import automation, { AudioAdjustmentOptions } from './automation.js';
import buildOptions, * as defaults from './defaults.js';

/**
 * Type representing a beat of a Track. Contains cancellation logic so third-parties can cancel specific
 * beat rules on a given Track. Also used for passing beat events to callbacks.
 */
export type TrackBeat = {
    time: number;
    isCancelled: boolean;

    /**
     * Cancels future beat events generated by this TrackBeat on a best-case basis.
     *
     * If the beat event was already scheduled, it may cause third-party listeners to be called anyway.
     * Tracks will always double-check that the TrackBeat they synchronized to was still active at the time,
     * rapidly stopping playback. In the worst case, a synchronized track may be audible for a brief moment.
     */
    cancel(): void;
};

/**
 * Enumeration for track beat types. If writing with TypeScript, use these.
 */
export enum TrackBeatType {
    /**
     * Repeating beat, firing every `S + xR` seconds where S is the start point and R is the repeat seconds
     */
    REPEATING = 'repeating',

    /**
     * Precise beat, fires on an exact time
     */
    PRECISE = 'precise',

    /**
     * Exclusion region, beats that would fire in this region... won't fire
     */
    EXCLUDE = 'exclude',
}

/**
 * Enumeration for track event types. If writing with TypeScript, use these.
 *
 * Deprecation Notice: Depending on how these are used or misused, some may be removed, added, or change
 * in future versions. In general, you should never tie any game logic to these events. Only use the
 * events for sound-specific things.
 */
export enum TrackEventType {
    /**
     * Fires when a track is scheduling to start playback.
     * - `startPlayback(track, startOptions)` => ({@link Track}, {@link AudioAdjustmentOptions})
     */
    START_PLAYBACK = 'startPlayback',

    /**
     * Fires when a track is scheduling to stop playback. If you need to fire when a playing AudioSource
     * goes silent, i.e. when it truly stops playing, use the {@link SILENCED} event instead.
     * - `stopPlayback(track, stopOptions)` => ({@link Track}, {@link AudioAdjustmentOptions})
     */
    STOP_PLAYBACK = 'stopPlayback',

    /**
     * - `beat(track, beat)` => ({@link Track}, {@link TrackBeat})
     */
    BEAT = 'beat',

    /**
     * Fires regularly from `requestAnimFrame()`. Naturally, this creates a performance hit the more
     * callbacks are tied to this event. If you have any sort of complexity, it's strongly suggested
     * to run your own rendering pipeline and directly access
     * - `position(track, time)` => ({@link Track}, `number`)
     */
    POSITION = 'position',

    /**
     * Fires when a playing AudioSource goes silent, i.e. its no longer playing. This uses the built-in
     * "ended" event on AudioBufferSourceNodes.
     * - `silenced(track, time)` => ({@link Track}, `number`)
     */
    SILENCED = 'silenced',
}

export enum TrackSwapType {
    /**
     * Ramps in the new source and then ramps out the old source
     */
    IN_OUT = 'inOut',

    /**
     * Ramps out the old source and then ramps in the new source
     */
    OUT_IN = 'outIn',

    /**
     * Ramps both sources at the same time
     */
    CROSS = 'cross',

    /**
     * Cuts directly from old source to the new source
     */
    CUT = 'cut',
}

/**
 * Simple adjustment options to use when swapping between two AudioSources on a track.
 * Includes all options from AudioAdjustmentOptions.
 */
export type TrackSwapOptions = AudioAdjustmentOptions & {
    /**
     * Order of operation when swapping sources
     */
    swap: TrackSwapType | null;

    /**
     * Delay between the end of the old source and the start of the new source.
     * To achieve the effect, implementations add the delay and duration of the
     * adjustment to this value, and use it as the starting delay on the new source.
     */
    swapDelay?: number;
};

/**
 * Advanced swap specification for swapping between two AudioSources on a track.
 * Both adjustments are applied simultaneously to each source. Internally, one
 * of these is produced from given {@link TrackSwapOptions} and used for swapping.
 */
export type TrackSwapAdvancedOptions = {
    oldSource: Required<AudioAdjustmentOptions>;
    newSource: Required<AudioAdjustmentOptions>;
};

/**
 * Track interface
 */
interface Track {
    /**
     * Allows receiving the final output of the Track. Advanced users only!
     *
     * @param destination the {@link AudioNode} or {@link AudioParam} to which to connect
     * @param outputIndex the output index to use, should be 0
     * @param inputIndex the input index into the {@link AudioNode} or {@link AudioParam}
     */
    connect(destination: AudioNode, outputIndex?: number, inputIndex?: number): AudioNode;
    connect(destination: AudioParam, outputIndex?: number): void;
    connect(destination: AudioNode | AudioParam, outputIndex?: number, inputIndex?: number): AudioNode | void;

    /**
     * Begin playback on the track, starting the loaded AudioSource.
     *
     * Implementation Notes:
     * - If this call follows a `loadSource()`, it will call `swap()` using a default OUT_IN swap.
     *   Merge the passed options with the default swap. Use `swap()` directly for more control.
     * - If the AudioSource attached to this Track is already playing, clone it as a new loaded source
     *   and call `swap()`, merging the passed options with the default swap options as above.
     * - Using `duration` is equivalent to calling `stop(delay + duration)` after this method returns.
     * @param delay optional delay time
     * @param options adjustment parameters for fading in the source
     * @param offset offset into the audio source to start playback from, with the same effects as
     *               offset from the [Web Audio API](https://developer.mozilla.org/en-US/docs/Web/API/AudioBufferSourceNode/start#offset)
     * @param duration how long to play before stopping
     * @returns {Track} this Track
     */
    start(): Track;
    start(options: AudioAdjustmentOptions): Track;
    start(delay: number, offset?: number, duration?: number): Track;
    start(offset: number, duration: number, options: AudioAdjustmentOptions): Track;

    /**
     * Stop playback on the track, pausing the currently playing AudioSource.
     *
     * Implementation Notes:
     * - Does nothing if there is no playing AudioSource.
     * - For consecutive calls, the earliest time from consecuitive calls will be used.
     * - Saves the playhead position of the AudioSource at the time this method is called,
     *   so that a future `start()` call will resume from the saved position.
     * @param delay optional delay time
     * @param options adjustment parameters for fading out the source
     * @returns {Track} this Track
     */
    stop(): Track;
    stop(delay: number): Track;
    stop(options: AudioAdjustmentOptions): Track;

    /**
     * Loads and immediately starts playback of an audio source.
     *
     * Implementation Notes:
     * - This is equivalent to calling `loadSource(path)`, then `play(...)`
     * @param path audio source path
     * @param options adjustment parameters for fading in the source
     * @param delay delay time
     * @param offset offset into the audio source to start playback from, with the same effects as
     *               offset from the [Web Audio API](https://developer.mozilla.org/en-US/docs/Web/API/AudioBufferSourceNode/start#offset)
     * @param duration how long to play before stopping
     * @returns {AudioSourceNode} the new AudioSource
     */
    playSource(path: string): AudioSourceNode;
    playSource(path: string, options: AudioAdjustmentOptions): AudioSourceNode;
    playSource(path: string, delay: number, offset?: number, duration?: number): AudioSourceNode;
    playSource(
        path: string,
        offset: number,
        duration: number,
        options: AudioAdjustmentOptions,
    ): AudioSourceNode;

    /**
     * Loads an audio source and returns it. The audio source will be linked to this track, so that
     * calling `start()` will play the last loaded audio source. You may use this to load a second
     * audio source while one is already playing, it will not be swapped until a call to `start()`
     * or `swap()` is made.
     * @param path audio source path
     * @param source source to use
     * @returns {AudioSourceNode} the new AudioSource
     */
    loadSource(path: string): AudioSourceNode;
    loadSource(source: AudioSourceNode): AudioSourceNode;

    /**
     * Retrieve the currently active source, the one that was most recently playing.
     */
    getActiveSource(): AudioSourceNode | null;

    /**
     * Retrieve the currently loaded source, the one that will start playing the next time start or
     * swap is called.
     */
    getLoadedSource(): AudioSourceNode | null;

    /**
     * Swaps the currently playing AudioSource with the loaded AudioSource.
     * If there is no loaded source from calling loadSource(), this method does nothing.
     *
     * Implementation Notes:
     * - Internally, this method should simply move the playing source onto the fadeout gain, and
     *   trigger a fadeout automation, then move the loaded source into the playing source, and
     *   call start() with the appropriate options
     * - Using `duration` is equivalent to calling `stop(delay + duration)` after this method returns.
     * @param delay delay time
     * @param offset offset into the audio source to start playback from, with the same effects as
     *               offset from the [Web Audio API](https://developer.mozilla.org/en-US/docs/Web/API/AudioBufferSourceNode/start#offset)
     * @param duration how long to play before stopping
     * @param options swap parameters
     * @returns {Track} this Track
     */
    swap(): Track;
    swap(delay: number, offset?: number, duration?: number): Track;
    swap(options: TrackSwapOptions | TrackSwapAdvancedOptions): Track;
    swap(offset: number, duration: number, options: TrackSwapOptions | TrackSwapAdvancedOptions): Track;

    /**
     * Set the volume of this track.
     * @param volume gain multiplier
     * @param options adjustment parameters
     * @returns {Track} this Track
     */
    volume(volume: number, options?: AudioAdjustmentOptions): Track;

    /**
     * Enabled/ disable a loop, and set timings.
     *
     * Implementation Notes:
     * - Uses the AudioBufferSourceNode built-in looping parameters directly
     * @param enabled true to enable looping
     * @param startSample point to loop back to, must be before `endSample`
     * @param endSample trigger point for the loop, must be after `startSample`
     * @returns {Track} this Track
     */
    loop(enabled: boolean, startSample?: number, endSample?: number): Track;

    /**
     * Enable/ disable a jump, and set timings.
     *
     * Implementation Notes:
     * - Uses a custom implementation that looks ahead to find the `fromSample`,
     *   then schedules a CUT swap to the `toSample`. As a result, this can also
     *   be used for looping, but that is provided separately so both can be used
     *   at the same time.
     * @param enabled true to enable jumping
     * @param fromSample trigger point for the jump
     * @param toSample point to jump to
     * @returns {Track} this Track
     */
    jump(enabled: boolean, fromSample?: number, toSample?: number): Track;

    /**
     * Create a beat rule and return it.
     *
     * Calling multiple times will stack beat rules. Use sparingly!
     * Returned TrackBeat can be used to cancel it later.
     * @param type beat type
     * @param origin origin point for this beat or range
     * @param period duration (exclude) or period (repeating), or does nothing (precise)
     * @returns {TrackBeat} the created TrackBeat
     */
    createBeat(type: TrackBeatType, origin: number, period?: number): TrackBeat;

    /**
     * Clears all beats on this track and cancels them
     * @returns {Track} this Track
     */
    clearBeats(): Track;

    /**
     * Schedules this track to start playback precisely when the given track generates a beat.
     * @param track track
     * @param options adjustment parameters
     * @returns {Track} this Track
     */
    syncPlayTo(track: Track, options?: AudioAdjustmentOptions): Track;

    /**
     * Schedules this track to stop playback precisely when the given track generates a beat.
     *
     * It is possible to synchronize a track to stop to itself.
     * @param track track
     * @param options adjustment parameters
     * @returns {Track} this Track
     */
    syncStopTo(track: Track, options?: AudioAdjustmentOptions): Track;

    /**
     * Assigns a callback to be called for the event. The first arguement is always the calling track.
     * @param type event to listen for
     * @param callback async function to execute
     * @returns {Track} this Track
     */
    listenFor(type: TrackEventType, callback: Promise<any>): Track;
}

//#region TrackSingle
/**
 * Track implementation
 */
class TrackSingle implements Track {
    /**
     * The master gain for the track, it is exposed for automation
     */
    private readonly gainNode: GainNode;

    /**
     * Internal gain node for fading in/ out the primary source, for stopping and starting
     */
    private readonly gainPrimaryNode: GainNode;

    /**
     * Internal gain node for fading in the secondary source, swapping primary sources
     */
    private readonly gainSecondaryNode: GainNode;

    /**
     * Tracks the most recently loaded source, used in swaping/ starting
     */
    private loadedSource?: AudioSourceNode;

    /**
     * Tracks the playing source, on which automations and stopping effect
     */
    private playingSource?: AudioSourceNode;

    /**
     * Stores a position, in seconds, on which stop() will save the playhead
     * position at the moment of activation, on which play() will resume from
     */
    private resumeMarker: number = 0;

    /**
     * Stores the earliest scheduled stop time, used to disable the ability to call
     * stop continuously with future times such that the underlying AudioSourceNode
     * never reaches a stop time.
     */
    private nextStopTime: number = 0;

    /**
     * Tracks whether or not the loadSource() method has previously been called,
     * used by start() to determine if a swap() or plain start() will occur.
     */
    private isLoadSourceCalled: boolean = false;

    /**
     * Tracks calls to the start method such that deferred start calls, using
     * the 'loaded' event listener, will abort on subsequent calls to start if
     * the time has been updated.
     *
     * This is necessary for the start method because future calls to start must
     * not be replaced by a deferred call that happened to execute after it
     * completed. If start is called many times, and they are all deferred, the
     * latest one should make the call as if it was the only call.
     */
    private lastStartCallTime: number = 0;

    /**
     * Tracks calls to the loop method such that deferred loop calls, using the
     * 'loaded' event listener, will abort on subsequent calls to loop if the
     * time has been updated.
     */
    private lastLoopCallTime: number = 0;

    /**
     * Implementation Notes:
     * - If the given AudioSourceNode has outgoing connections, they will be disconnected at the
     *   time this Track begins playback of the AudioSourceNode.
     * - Providing an AudioSourceNode that is controlled by another Track has undefined behavior.
     *   If you must reuse an AudioSourceNode that may be controlled by another Track, use the
     *   clone() method to obtain a new node.
     * @param name
     * @param audioContext
     * @param destination
     * @param source
     */
    constructor(
        private readonly name: string,
        private readonly audioContext: AudioContext,
        destination: AudioNode,
        source?: AudioSourceNode,
    ) {
        this.gainNode = audioContext.createGain();
        this.gainNode.connect(destination);
        this.loadedSource = source;

        this.gainPrimaryNode = audioContext.createGain();
        this.gainSecondaryNode = audioContext.createGain();
        this.gainPrimaryNode.connect(this.gainNode);
        this.gainSecondaryNode.connect(this.gainNode);
    }

    public toString(): string {
        return `TrackSingle[${this.name}] with context ${this.audioContext}`;
    }

    public connect(destination: AudioNode, outputIndex?: number, inputIndex?: number): AudioNode;
    public connect(destination: AudioParam, outputIndex?: number): void;
    public connect(
        destination: AudioNode | AudioParam,
        outputIndex?: number,
        inputIndex?: number,
    ): AudioNode | void {
        if (destination instanceof AudioNode) {
            return this.gainNode.connect(destination, outputIndex, inputIndex);
        } else if (destination instanceof AudioParam) {
            return this.gainNode.connect(destination, outputIndex);
        } else {
            console.warn(
                `Cannot connect to type ${(destination as any)?.constructor?.name}. This is likely a mistake.`,
            );
        }
    }

    public start(): Track;
    public start(options: AudioAdjustmentOptions): Track;
    public start(delay: number, offset?: number, duration?: number): Track;
    public start(offset: number, duration: number, options: AudioAdjustmentOptions): Track;
    start(
        optionsOrDelayOrOffset?: number | AudioAdjustmentOptions,
        offsetOrDuration?: number,
        optionsOrDuration?: number | AudioAdjustmentOptions,
    ): Track {
        let options: AudioAdjustmentOptions | undefined;
        let delay: number | undefined;
        let offset: number | undefined;
        let duration: number | undefined;
        if (typeof optionsOrDelayOrOffset == 'number') {
            if (optionsOrDuration == undefined || typeof optionsOrDuration == 'number') {
                delay = optionsOrDelayOrOffset;
                offset = offsetOrDuration;
                duration = optionsOrDuration;
            } else {
                offset = optionsOrDelayOrOffset;
                duration = offsetOrDuration;
                options = optionsOrDuration;
            }
        } else {
            options = optionsOrDelayOrOffset;
        }

        this.lastStartCallTime = this.audioContext.currentTime;

        // Implicitly load a copy of the same source to call swap
        if (this.playingSource?.isActive && !this.loadedSource) {
            this.loadedSource = this.playingSource.clone(this);
            this.loadedSource.hrtfPanner = this.playingSource.hrtfPanner;
            this.isLoadSourceCalled = true;
        }

        // Swap after loading a source with loadSource()
        if (this.playingSource?.isActive && this.isLoadSourceCalled && this.loadedSource) {
            if (delay) {
                return this.swap(delay, offset, duration);
            }

            const swapOptions = buildOptions(options, defaults.trackSwapOutIn);
            if (offset != undefined && duration != undefined) {
                return this.swap(offset, duration, swapOptions);
            }

            return this.swap(swapOptions);
        }

        const startOptions = buildOptions(options, defaults.startImmediate);
        if (delay != undefined) {
            startOptions.delay += delay;
        }

        // Move the loaded source into the playing source
        let sourceChanged = false;
        if (this.loadedSource) {
            this.loadedSource.disconnect(); // claim the loadedSource
            if (this.playingSource) {
                if (this.playingSource.isActive) {
                    const fadeOut = structuredClone(defaults.automationNatural);
                    this.playingSource.volume(0, fadeOut);
                    this.playingSource.stop(this._time + fadeOut.delay + fadeOut.duration);
                    if (this.playingSource.owner == this) {
                        setTimeout(this.playingSource.destroy, fadeOut.delay + fadeOut.duration);
                    }
                } else if (this.playingSource.owner == this) {
                    this.playingSource.destroy();
                }
            }
            this.playingSource = this.loadedSource;
            this.gainPrimaryNode.gain.value = 0;
            this.playingSource.connect(this.gainPrimaryNode);
            this.loadedSource = undefined;
            this.isLoadSourceCalled = false;
            sourceChanged = true;
        }

        if (!this.playingSource) {
            console.warn('Track.start() called with no source loaded. This is likely a mistake.');
            return this;
        }

        if (this.playingSource.isDestroyed) {
            if (this.playingSource.owner == this) {
                console.warn(`Track's playingSource was unexpectedly destroyed. This is likely a mistake.`);
            }
            this.playingSource = undefined;
            return this;
        }

        if (this.playingSource.buffer) {
            this.playingSource.start(
                this._time + startOptions.delay,
                offset || (!sourceChanged ? this.resumeMarker : 0),
            );
        } else if (!this.playingSource.isLoaded) {
            const self = this;
            const expectedCallTime = this.lastStartCallTime;
            this.playingSource.addEventListener(
                'loaded',
                (event) => {
                    if (
                        !event.target.isDestroyed &&
                        self.lastStartCallTime - expectedCallTime < Number.EPSILON
                    ) {
                        event.target.start(
                            self._time + startOptions.delay,
                            offset || (!sourceChanged ? self.resumeMarker : 0),
                        );
                    }
                },
                { once: true },
            );
        } else {
            console.warn(
                `Track's AudioSourceNode seems to be in an invalid state. ` +
                    `There is no buffer, yet load() has completed previously. ` +
                    `Have you deliberately set the AudioSourceNode buffer to null?`,
            );
            return this;
        }

        automation(this.audioContext, this.gainPrimaryNode.gain, 1, startOptions, true);

        this.nextStopTime = 0;
        this.resumeMarker = 0;

        if (duration != undefined) {
            this.stop(startOptions.delay + duration);
        }

        return this;
    }

    public stop(): Track;
    public stop(delay: number): Track;
    public stop(options: AudioAdjustmentOptions): Track;
    stop(delayOrOptions?: number | AudioAdjustmentOptions): Track {
        let delay: number | undefined;
        let options: AudioAdjustmentOptions | undefined;
        if (typeof delayOrOptions == 'number') {
            delay = delayOrOptions;
        } else {
            options = delayOrOptions;
        }

        if (!this.playingSource?.isActive) {
            return this;
        }

        const position = this.playingSource.position();
        if (position != -1) {
            this.resumeMarker = position;
        }

        const stopOptions = buildOptions(options, defaults.stopImmediate);
        if (delay != undefined) {
            stopOptions.delay += delay;
        }

        const scheduledStop = this._time + stopOptions.delay + stopOptions.duration;
        if (this.nextStopTime == 0 || scheduledStop < this.nextStopTime) {
            this.nextStopTime = scheduledStop;
        }
        this.playingSource.stop(this.nextStopTime);
        automation(this.audioContext, this.gainPrimaryNode.gain, 0, stopOptions, true);

        return this;
    }

    public playSource(path: string): AudioSourceNode;
    public playSource(path: string, options: AudioAdjustmentOptions): AudioSourceNode;
    public playSource(path: string, delay: number, offset?: number, duration?: number): AudioSourceNode;
    public playSource(
        path: string,
        offset: number,
        duration: number,
        options: AudioAdjustmentOptions,
    ): AudioSourceNode;
    playSource(
        path: string,
        optionsOrDelayOrOffset?: AudioAdjustmentOptions | number,
        offsetOrDuration?: number,
        optionsOrDuration?: number | AudioAdjustmentOptions,
    ): AudioSourceNode {
        let options: AudioAdjustmentOptions | undefined;
        let delay: number | undefined;
        let offset: number | undefined;
        let duration: number | undefined;

        if (typeof optionsOrDelayOrOffset == 'number') {
            if (optionsOrDuration == undefined || typeof optionsOrDuration == 'number') {
                delay = optionsOrDelayOrOffset;
                offset = offsetOrDuration;
                duration = optionsOrDuration;
            } else {
                offset = optionsOrDelayOrOffset;
                duration = offsetOrDuration;
                options = optionsOrDuration;
            }
        } else {
            options = optionsOrDelayOrOffset;
        }

        const audioSource = this.loadSource(path);
        if (delay) {
            this.start(delay, offset, duration);
        } else if (options) {
            if (offset != undefined && duration != undefined) {
                this.start(offset, duration, options);
            } else {
                this.start(options);
            }
        } else {
            this.start();
        }

        return audioSource;
    }

    public loadSource(path: string): AudioSourceNode;
    public loadSource(source: AudioSourceNode): AudioSourceNode;
    public loadSource(pathOrSource: string | AudioSourceNode): AudioSourceNode {
        if (this.loadedSource?.owner == this) {
            this.loadedSource.destroy();
        }
        if (typeof pathOrSource == 'string') {
            this.loadedSource = new AudioSourceNode(this.audioContext, this);
            this.loadedSource.load(pathOrSource);
        } else {
            this.loadedSource = pathOrSource;
        }
        this.isLoadSourceCalled = true;
        return this.loadedSource;
    }

    public getActiveSource(): AudioSourceNode | null {
        return this.playingSource ?? null;
    }

    public getLoadedSource(): AudioSourceNode | null {
        return this.loadedSource ?? null;
    }

    public swap(): Track;
    public swap(delay: number, offset?: number, duration?: number): Track;
    public swap(options: TrackSwapOptions | TrackSwapAdvancedOptions): Track;
    public swap(
        offset: number,
        duration: number,
        options: TrackSwapOptions | TrackSwapAdvancedOptions,
    ): Track;
    swap(
        optionsOrDelayOrOffset?: TrackSwapOptions | TrackSwapAdvancedOptions | number,
        offsetOrDuration?: number,
        optionsOrDuration?: number | TrackSwapOptions | TrackSwapAdvancedOptions,
    ): Track {
        if (!this.isLoadSourceCalled) {
            return this;
        }
        this.isLoadSourceCalled = false;

        if (!this.loadedSource) {
            console.warn(
                'Track has an invalid state, loadSource() seems to have been recently called, ' +
                    'but there is no loaded source. This is a mistake.',
            );
            return this;
        }
        const originalSource = this.playingSource;
        this.playingSource = undefined;

        let options: TrackSwapOptions | TrackSwapAdvancedOptions | undefined;
        let delay: number | undefined;
        let offset: number | undefined;
        let duration: number | undefined;
        if (typeof optionsOrDelayOrOffset == 'number') {
            if (optionsOrDuration == undefined || typeof optionsOrDuration == 'number') {
                delay = optionsOrDelayOrOffset;
                offset = offsetOrDuration;
                duration = optionsOrDuration;
            } else {
                offset = optionsOrDelayOrOffset;
                duration = offsetOrDuration;
                options = optionsOrDuration;
            }
        } else {
            options = optionsOrDelayOrOffset;
        }

        const swapOptions = buildOptions(options, defaults.trackSwapDefault);
        if (delay != undefined) {
            swapOptions.newSource.delay += delay;
            swapOptions.oldSource.delay += delay;
        }

        if (originalSource) {
            this.gainSecondaryNode.gain.value = this.gainPrimaryNode.gain.value;
            originalSource.connect(this.gainSecondaryNode);
            originalSource.disconnect(this.gainPrimaryNode);
            originalSource.stop(this._time + swapOptions.oldSource.delay + swapOptions.oldSource.duration);
            automation(this.audioContext, this.gainSecondaryNode.gain, 0, swapOptions.oldSource);
            if (originalSource.owner == this) {
                setTimeout(
                    originalSource.destroy,
                    swapOptions.oldSource.delay + swapOptions.oldSource.duration,
                );
            }
        }

        if (offset != undefined && duration != undefined) {
            return this.start(offset, duration, swapOptions.newSource);
        }

        return this.start(swapOptions.newSource);
    }

    public volume(volume: number, options?: AudioAdjustmentOptions): Track {
        automation(
            this.audioContext,
            this.gainNode.gain,
            volume,
            buildOptions(options, defaults.automationDefault),
        );
        return this;
    }

    public loop(enabled: boolean, startSample?: number, endSample?: number): Track {
        const source = this.playingSource ?? this.loadedSource;
        this.lastLoopCallTime = this.audioContext.currentTime;
        if (source && !source.isDestroyed) {
            if (source.buffer?.sampleRate) {
                source.loop = enabled;
                if (startSample != undefined) {
                    source.loopStart = startSample / source.buffer.sampleRate;
                }
                if (endSample != undefined) {
                    source.loopEnd = endSample / source.buffer.sampleRate;
                }
            } else if (!source.isLoaded) {
                const self = this;
                const expectedCallTime = this.lastLoopCallTime;
                source.addEventListener(
                    'loaded',
                    (event) => {
                        if (
                            !event.target.isDestroyed &&
                            self.lastLoopCallTime - expectedCallTime < Number.EPSILON
                        ) {
                            self.loop(enabled, startSample, endSample);
                        }
                    },
                    {
                        once: true,
                    },
                );
                return this;
            } else {
                console.warn(
                    `Track's AudioSourceNode seems to be in an invalid state. ` +
                        `There is no buffer, yet load() has completed previously. ` +
                        `Have you deliberately set the AudioSourceNode buffer to null?`,
                );
                return this;
            }
        }
        return this;
    }

    public jump(enabled: boolean, fromSample?: number, toSample?: number): Track {
        console.log(`stub jump ${enabled} from ${fromSample} to ${toSample}`);
        return this;
    }

    public createBeat(type: TrackBeatType, origin: number, period?: number): TrackBeat {
        console.log(`stub createBeat of ${type} at ${origin} with period ${period}`);
        return { time: 0, isCancelled: false, cancel: () => {} };
    }

    public clearBeats(): Track {
        console.log('stub clearBeats');
        return this;
    }

    public syncPlayTo(track: Track, options?: AudioAdjustmentOptions): Track {
        console.log(`stub syncPlayTo ${track} with options ${options}`);
        return this;
    }

    public syncStopTo(track: Track, options?: AudioAdjustmentOptions): Track {
        console.log(`stub syncStopTo ${track} with options ${options}`);
        return this;
    }

    public listenFor(type: TrackEventType, callback: Promise<any>): Track {
        console.log(`stub listenFor ${type} calling ${callback}`);
        return this;
    }

    private get _time(): number {
        return this.audioContext.currentTime;
    }
}
// #endregion TrackSingle

// #region TrackGroup
/**
 * TrackGroup. All TrackGroups are constructed with a primary Track that shares the same name as the group,
 * to which most methods will operate as a transparent call onto the primary Track. Unless otherwise stated
 * by the method's documentation, assume it acts directly onto the primary Track.
 */
class TrackGroup implements Track {
    private tracks: {
        [name: string]: Track;
    } = {};

    private readonly gainNode: GainNode;

    constructor(
        private readonly name: string,
        private readonly audioContext: AudioContext,
        destination: AudioNode,
        source?: AudioSourceNode,
    ) {
        this.gainNode = audioContext.createGain();
        this.gainNode.connect(destination);

        const track = new TrackSingle(name, audioContext, this.gainNode, source);
        this.tracks[name] = track;
    }

    toString(): string {
        return `TrackGroup[${this.name}] with context ${this.audioContext}`;
    }

    public connect(destination: AudioNode, outputIndex?: number, inputIndex?: number): AudioNode;
    public connect(destination: AudioParam, outputIndex?: number): void;
    public connect(
        destination: AudioNode | AudioParam,
        outputIndex?: number,
        inputIndex?: number,
    ): AudioNode | void {
        if (destination instanceof AudioNode) {
            return this.gainNode.connect(destination, outputIndex, inputIndex);
        } else if (destination instanceof AudioParam) {
            return this.gainNode.connect(destination, outputIndex);
        } else {
            console.warn(
                `Cannot connect to type ${(destination as any)?.constructor?.name}. This is likely a mistake.`,
            );
        }
    }

    /**
     * Retrieve a track by its name.
     *
     * @param name track name
     * @returns {Track} if found, `undefined` otherwise
     */
    public track(name: string): Track | undefined {
        return this.tracks[name];
    }

    /**
     * Retrieve the primary Track for this TrackGroup. It will share the name of this TrackGroup
     * and is guaranteed* to exist.
     *
     * \* Unless you do some funny business and delete it!
     *
     * @returns {Track} the primary Track of this TrackGroup
     */
    public primaryTrack(): Track {
        return this.tracks[this.name] as Track;
    }

    /**
     * Add a new track to this group.
     * @param name name of the track
     * @param path path to audio source
     * @param source loaded audio source
     * @returns {Track} the new Track
     */
    public newTrack(name: string): Track;
    public newTrack(name: string, path: string): Track;
    public newTrack(name: string, source: AudioSourceNode): Track;
    public newTrack(name: string, pathOrSource?: string | AudioSourceNode): Track {
        if (name == this.name) {
            throw new Error(`Cannot use name "${name}" as it is the name of this group track`);
        }
        if (Object.keys(this.tracks).includes(name)) {
            throw new Error(`Cannot use name "${name}" as it already exists in this group track`);
        }

        const track = new TrackSingle(name, this.audioContext, this.gainNode);
        if (pathOrSource != undefined) {
            if (typeof pathOrSource == 'string') {
                track.loadSource(pathOrSource);
            } else {
                track.loadSource(pathOrSource);
            }
        }

        this.tracks[name] = track;
        return track;
    }

    /**
     * Starts playback of all tracks in this group.
     */
    public start(): Track;
    public start(options: AudioAdjustmentOptions): Track;
    public start(delay: number, offset?: number, duration?: number): Track;
    public start(offset: number, duration: number, options: AudioAdjustmentOptions): Track;
    start(
        optionsOrDelayOrOffset?: number | AudioAdjustmentOptions,
        offsetOrDuration?: number,
        optionsOrDuration?: number | AudioAdjustmentOptions,
    ): Track {
        let options: AudioAdjustmentOptions | undefined;
        let delay: number | undefined;
        let offset: number | undefined;
        let duration: number | undefined;
        if (typeof optionsOrDelayOrOffset == 'number') {
            if (optionsOrDuration == undefined || typeof optionsOrDuration == 'number') {
                delay = optionsOrDelayOrOffset;
                offset = offsetOrDuration;
                duration = optionsOrDuration;
            } else {
                offset = optionsOrDelayOrOffset;
                duration = offsetOrDuration;
                options = optionsOrDuration;
            }
        } else {
            options = optionsOrDelayOrOffset;
        }

        if (delay) {
            for (const track in this.tracks) {
                this.tracks[track]?.start(delay, offset, duration);
            }
        } else if (options) {
            if (offset != undefined && duration != undefined) {
                for (const track in this.tracks) {
                    this.tracks[track]?.start(offset, duration, options);
                }
            } else {
                for (const track in this.tracks) {
                    this.tracks[track]?.start(options);
                }
            }
        } else {
            for (const track in this.tracks) {
                this.tracks[track]?.start();
            }
        }

        return this;
    }

    /**
     * Stops playback of all tracks in this group.
     */
    public stop(): Track;
    public stop(delay: number): Track;
    public stop(options: AudioAdjustmentOptions): Track;
    stop(delayOrOptions?: number | AudioAdjustmentOptions): Track {
        let delay: number | undefined;
        let options: AudioAdjustmentOptions | undefined;
        if (typeof delayOrOptions == 'number') {
            delay = delayOrOptions;
        } else {
            options = delayOrOptions;
        }

        if (delay) {
            for (const track in this.tracks) {
                this.tracks[track]?.stop(delay);
            }
        } else if (options) {
            for (const track in this.tracks) {
                this.tracks[track]?.stop(options);
            }
        } else {
            for (const track in this.tracks) {
                this.tracks[track]?.stop();
            }
        }

        return this;
    }

    public playSource(path: string): AudioSourceNode;
    public playSource(path: string, options: AudioAdjustmentOptions): AudioSourceNode;
    public playSource(path: string, delay: number, offset?: number, duration?: number): AudioSourceNode;
    public playSource(
        path: string,
        offset: number,
        duration: number,
        options: AudioAdjustmentOptions,
    ): AudioSourceNode;
    playSource(
        path: string,
        optionsOrDelayOrOffset?: AudioAdjustmentOptions | number,
        offsetOrDuration?: number,
        optionsOrDuration?: number | AudioAdjustmentOptions,
    ): AudioSourceNode {
        let options: AudioAdjustmentOptions | undefined;
        let delay: number | undefined;
        let offset: number | undefined;
        let duration: number | undefined;

        if (typeof optionsOrDelayOrOffset == 'number') {
            if (optionsOrDuration == undefined || typeof optionsOrDuration == 'number') {
                delay = optionsOrDelayOrOffset;
                offset = offsetOrDuration;
                duration = optionsOrDuration;
            } else {
                offset = optionsOrDelayOrOffset;
                duration = offsetOrDuration;
                options = optionsOrDuration;
            }
        } else {
            options = optionsOrDelayOrOffset;
        }

        if (delay) {
            return this.primaryTrack().playSource(path, delay, offset, duration);
        } else if (options) {
            if (offset != undefined && duration != undefined) {
                return this.primaryTrack().playSource(path, offset, duration, options);
            } else {
                return this.primaryTrack().playSource(path, options);
            }
        } else {
            return this.primaryTrack().playSource(path);
        }
    }

    public loadSource(path: string): AudioSourceNode;
    public loadSource(source: AudioSourceNode): AudioSourceNode;
    public loadSource(pathOrSource: string | AudioSourceNode): AudioSourceNode {
        if (typeof pathOrSource == 'string') {
            return this.primaryTrack().loadSource(pathOrSource);
        } else {
            return this.primaryTrack().loadSource(pathOrSource);
        }
    }

    public getActiveSource(): AudioSourceNode | null {
        return this.primaryTrack().getActiveSource();
    }

    public getLoadedSource(): AudioSourceNode | null {
        return this.primaryTrack().getLoadedSource();
    }

    public swap(): Track;
    public swap(delay: number, offset?: number, duration?: number): Track;
    public swap(options: TrackSwapOptions | TrackSwapAdvancedOptions): Track;
    public swap(
        offset: number,
        duration: number,
        options: TrackSwapOptions | TrackSwapAdvancedOptions,
    ): Track;
    swap(
        optionsOrDelayOrOffset?: TrackSwapOptions | TrackSwapAdvancedOptions | number,
        offsetOrDuration?: number,
        optionsOrDuration?: number | TrackSwapOptions | TrackSwapAdvancedOptions,
    ): Track {
        let options: TrackSwapOptions | TrackSwapAdvancedOptions | undefined;
        let delay: number | undefined;
        let offset: number | undefined;
        let duration: number | undefined;
        if (typeof optionsOrDelayOrOffset == 'number') {
            if (optionsOrDuration == undefined || typeof optionsOrDuration == 'number') {
                delay = optionsOrDelayOrOffset;
                offset = offsetOrDuration;
                duration = optionsOrDuration;
            } else {
                offset = optionsOrDelayOrOffset;
                duration = offsetOrDuration;
                options = optionsOrDuration;
            }
        } else {
            options = optionsOrDelayOrOffset;
        }

        if (delay) {
            return this.primaryTrack().swap(delay, offset, duration);
        } else if (options) {
            if (offset != undefined && duration != undefined) {
                return this.primaryTrack().swap(offset, duration, options);
            } else {
                return this.primaryTrack().swap(options);
            }
        } else {
            return this.primaryTrack().swap();
        }
    }

    /**
     * Adjusts the volume output of this group.
     */
    public volume(volume: number, options?: AudioAdjustmentOptions): Track {
        automation(
            this.audioContext,
            this.gainNode.gain,
            volume,
            buildOptions(options, defaults.automationDefault),
        );
        return this;
    }

    public loop(enabled: boolean, startSample?: number, endSample?: number): Track {
        this.primaryTrack().loop(enabled, startSample, endSample);
        return this;
    }

    public jump(enabled: boolean, fromSample?: number, toSample?: number): Track {
        this.primaryTrack().jump(enabled, fromSample, toSample);
        return this;
    }

    public createBeat(type: TrackBeatType, origin: number, period?: number): TrackBeat {
        return this.primaryTrack().createBeat(type, origin, period);
    }

    /**
     * Clears beats across all tracks in the group.
     */
    public clearBeats(): Track {
        for (const track in this.tracks) {
            this.tracks[track]?.clearBeats();
        }
        return this;
    }

    /**
     * Synchronizes playback of all tracks in the group.
     */
    public syncPlayTo(track: Track, options?: AudioAdjustmentOptions): Track {
        for (const t in this.tracks) {
            this.tracks[t]?.syncPlayTo(track, options);
        }
        return this;
    }

    /**
     * Synchronizes stopping of all track in the group.
     */
    public syncStopTo(track: Track, options?: AudioAdjustmentOptions): Track {
        for (const t in this.tracks) {
            this.tracks[t]?.syncStopTo(track, options);
        }
        return this;
    }

    public listenFor(type: TrackEventType, callback: Promise<any>): Track {
        this.primaryTrack().listenFor(type, callback);
        return this;
    }
}
// #endregion TrackGroup

export default TrackSingle;
export { Track, TrackGroup };
